# 参考

1. pyTorch官方API文档。
2. Dougherty, James, Ron Kohavi, and Mehran Sahami. (1995). “Supervised and Unsupervised Discretization of Continuous Features.” Proceedings of the 12th International Conference on Machine Learning.
3. Collobert, Ronan, and Jason Weston. (2008). “A Unified Architecture for Natural Language Processing: Deep Neural Networks with Multitask Learning.” Proceedings of the 25th International Conference on Machine Learning.

<hr>

1虽然神经网络和NLP的历史悠久而丰富，但Collobert和Weston（2008）经常被认为是对NLP采用现代风格应用深度学习的先驱。

2分类变量是一个采用一组固定值的变量;例如，{TRUE，FALSE}，{VERB，NOUN，ADJECTIVE，...}，以及更多其他的。

3深度学习与2006年之前的文献中讨论的传统神经网络不同，它指的是越来越多的技术，通过
添加更多的网络工作.在章节3和4中我们会研究为什么这很重要。

4. “序数”分类是多类分类问题，其中标签之间存在部分顺序。在我们的年龄示例中，类别“0-18”出现在“19-25”之前，依此类推。

5. Seppo Linnainmaa首先在计算图上引入了自动微分的想法，作为他1970年硕士论文的一部分！其中的变体成为现代深度学习框架的基础，如Theano，TensorFlow和PyTorch。

6从v1.7开始，TensorFlow有一个“急切模式（eager mode）”，它使得在执行之前无需编译图形，但静态图仍然是TensorFlow的支柱。

7您可以在本书的gitHub repo中的 */chapters/chapter_1/PyTorch_Basics.ipynb* 下找到此部分的代码。

8标准正态分布是正态分布，均值`= 0`且方差`= 1`，

9这意味着如果你有一个非NVIDIA GPU，比如说AMD或ARM，那么你在写这篇文章时就不走运了（当然，你仍然可以在CPU模式下使用PyTorch）。但是，他可能会改变
uture。
