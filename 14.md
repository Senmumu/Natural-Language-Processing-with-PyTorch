图13。用于编码的句子one-hot编码：“Time flies like an arrow”和“Fruit flies like a
banana.”

注意
在这一点上，如果你不快地发现了我们混淆了两种不同的含义（或感觉）
“苍蝇”，祝贺的，聪明的读者！语言是充满了暧昧的，但我们仍然可以
通过使惊人的简化假设，建立有用的解决方案。它可以学习
特定场景的编码，但我们现在正在超越自我的。

虽然我们很少会在这本书中使用其他任何比one-hot表示用于输入，
现在我们将介绍*Term-Frequency*（TF）和 *Term-Frequency-Inverse-Document-Frequency*
（TFIDF）表示。这样做是因为他们在NLP普及，由于历史的原因，和
为了完整起见。这些表示在信息检索历史悠久（IR）
并积极采用即使在今天，在生产NLP系统。
TF表示
一个短语，句子，或文档的TF表示仅仅是onehot的总和
其构成词表示。要继续与我们的愚蠢的例子，使用上述
onehot编码，句子“果蝇像时光飞逝水果”有以下TF表示：
[1，2,2，1，1，0，0，0]。请注意，每个条目的次数数的计数
对应的词出现在句子（文集）。我们表示一个字的W进行TF（W）的TF。
实施例11。生成“坍塌”使用scikitlearn onehot或二进制表示
```
from sklearn.feature_extraction.text import CountVectorizer
import seaborn as sns
corpus = ['Time flies flies like an arrow.',
          'Fruit flies like a banana.']
one_hot_vectorizer = CountVectorizer(binary=True)
one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()
sns.heatmap(one_hot, annot=True,
            cbar=False, xticklabels=vocab,
            yticklabels=['Sentence 2'])
```
