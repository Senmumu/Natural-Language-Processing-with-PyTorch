例1-17 将CUDA张量与CPU绑定张量混合

- input 0

```python
y = torch.rand(3, 3) x+y
```

- output 0
```
------------------------------------------------- 
RuntimeError Traceback (most recent call last)
1 y = torch.rand(3, 3) ---> 2 x + y
RuntimeError: Expected object of type
torch.cuda.FloatTensor but found type torch.FloatTensor for argument #3 '
```
- input 1
```python
cpu_device = torch.device("cpu") 
y = y.to(cpu_device)
x = x.to(cpu_device)
x+y
```
- output 1
```
tensor([[ 0.7159, 1.0685, 1.3509], [ 0.3912, 0.2838, 1.3202],
[ 0.2967, 0.0420, 0.6559]])
```
请记住，从GPU来回移动数据是很昂贵的。 因此，典型的过程涉及在GPU上执行许多可并行化的计算，然后将最终结果传送回CPU。 这将允许您充分利用GPU。 如果您有多个CUDAvisible设备（即多个GPU），最佳做法是在执行程序时使用CUDA_VISIBLE_DEVICES环境变量，如下所示：

```sh
CUDA_VISIBLE_DEVICES=0,1,2,3 python main.py
```

作为本书的一部分，我们不涉及并行性和multiGPU培训，但它们在扩展实验中是必不可少的，有时甚至是训练大型模型。 我们建议您参考
yTorch文档和论坛，以获得有关此主题的其他帮助和支持。
# 练习
掌握主题的最佳方法是解决问题。 这里有一些热身练习。 许多问题需要经过官方的观察并找到有用的功能。
1.创建2D张量，然后添加在尺寸0处插入的尺寸为1的尺寸。
2.删除刚添加到先前张量的额外尺寸。
3.在区间[3,7]中创建一个形状为5x3的随机张量
4.使用正态分布中的值创建张量（mean = 0，std = 1）。
5.检索张量torch.Tensor（[1,1,1,0,1]）中所有非零元素的索引。
