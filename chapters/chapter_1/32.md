。创建一个大小为(3,1)的随机张量，然后将四个副本水平堆叠在一起。

7.返回两个三维矩阵的批量矩阵矩阵乘积
`(a = torch.rand(3,4,5)，b = torch.rand(3,5,4))`。

8.返回3D矩阵和2D矩阵的批量矩阵矩阵乘积
`(a = torch.rand(3,4,5)，b = torch.rand(5,4))`。
解决方案

1. `a = torch.rand(3,3)a.unsqueeze(0)`

2. `a.squeeze(0)`

3. `3 + torch.rand(5,3)`

4. `a = torch.rand(3,3)`
`a.normal_()`

5. `a = torch.Tensor([1，`
  `torch.nonzero(a)`中

6. `a = torch.rand(3,1)`
  `a.expand(3,4)`

7. `a = torch.rand(3, 4, 5)`
    `b = torch.rand(3, 5, 4)`
    `torch.bmm(a, b)`
8. `a = torch.rand(3,4,5)`
    `b = torch.rand(5,4)`
    
    `torch.bmm(a，b.unsqueeze(0).expand(a.size(0)，* b.size())`
# 小结
在本章中，我们介绍了本书的主要内容 - 自然语言处理(NLP)和深度学习 - 并对监督学习范式进行了详细的理解。您现在应该熟悉或至少知道各种相关术语，例如观察，目标，模型，参数，预测，损失函数，表示，学习/训练和推理。您还了解了如何使用onehot编码对学习任务的输入(观察和目标)进行编码，我们还检查了基于计数的表示，如TF和TFIDF。我们首先探索计算图是什么，然后考虑静态与动态计算图并参观PyTorch的张量操纵操作，开始了我们的PyTorch之旅。在第2章中，我们提供了传统NLP的概述。如果您对本书的主题不熟悉并为其他章节做好准备，这两章应该为您奠定必要的基础。
