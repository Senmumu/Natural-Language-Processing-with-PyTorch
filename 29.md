- input 0
```python
import torch
x = torch.ones(2, 2, requires_grad=True) 
describe(x)
print(x.grad is None)
```

- output 0
```
Type: torch.FloatTensor 
Shape/size: torch.Size([2, 2]) 
Values:
tensor([[ 1., 1.],
[ 1., 1.]]) True
```

- input 1
```python
y = (x + 2) * (x + 5) + 3 
describe(y)
print(x.grad is None)
```

- output 1
```
Type: torch.FloatTensor 
Shape/size: torch.Size([2, 2]) 
Values:
tensor([[ 21., 21.],
[ 21., 21.]]) True
```

- input 2
```python
z = y.mean()
describe(z) 
z.backward() 
print(x.grad is None)
```

- output 2
```
Type: torch.FloatTensor 
Shape/size: torch.Size([]) 
Values:
21.0
False
```

当您使用`requires_grad = True`创建张量时，您需要PyTorch来管理计算渐变的簿记信息。 首先，PyTorch将跟踪前向传球的值。 然后，在计算结束时，使用单个标量来计算后向传递。 通过在评估损失函数时产生的张量上使用`backward（）`方法来启动向后传递。 向后传递计算参与正向传递的张量对象的梯度值。
通常，梯度是表示函数输出相对于函数输入的斜率的值。 在计算图设置中，模型中的每个参数都存在梯度，可以将其视为参数对误差信号的贡献。 在PyTorch中，您可以使用.grad成员变量访问计算图中节点的渐变。 优化器使用`.grad`变量来更新参数的值。
